version: '3.8'

services:
  webui:
    build:
      context: .
      dockerfile: Dockerfile
      args:
        USE_CUDA: ${USE_CUDA:-false}
        USE_OLLAMA: ${USE_OLLAMA:-false}
        USE_CUDA_VER: ${USE_CUDA_VER:-cu121}
        USE_EMBEDDING_MODEL: ${USE_EMBEDDING_MODEL:-sentence-transformers/all-MiniLM-L6-v2}
        USE_RERANKING_MODEL: ${USE_RERANKING_MODEL:-""}
        BUILD_HASH: ${BUILD_HASH:-dev-build}
    environment:
      ENV: prod
      PORT: 8080
      USE_OLLAMA_DOCKER: ${USE_OLLAMA:-false}
      USE_CUDA_DOCKER: ${USE_CUDA:-false}
      USE_CUDA_DOCKER_VER: ${USE_CUDA_VER:-cu121}
      USE_EMBEDDING_MODEL_DOCKER: ${USE_EMBEDDING_MODEL:-sentence-transformers/all-MiniLM-L6-v2}
      USE_RERANKING_MODEL_DOCKER: ${USE_RERANKING_MODEL:-""}
      OLLAMA_BASE_URL: '/ollama'
      OPENAI_API_BASE_URL: ${OPENAI_API_BASE_URL}
      OPENAI_API_KEY: ${OPENAI_API_KEY}
      WEBUI_SECRET_KEY: ${WEBUI_SECRET_KEY:-""}
      SCARF_NO_ANALYTICS: 'true'
      DO_NOT_TRACK: 'true'
      ANONYMIZED_TELEMETRY: 'false'
      WHISPER_MODEL: 'base'
      WHISPER_MODEL_DIR: '/app/backend/data/cache/whisper/models'
      RAG_EMBEDDING_MODEL: ${USE_EMBEDDING_MODEL:-sentence-transformers/all-MiniLM-L6-v2}
      RAG_RERANKING_MODEL: ${USE_RERANKING_MODEL:-""}
      SENTENCE_TRANSFORMERS_HOME: '/app/backend/data/cache/embedding/models'
      HF_HOME: '/app/backend/data/cache/embedding/models'
      WEBUI_BUILD_VERSION: ${BUILD_HASH:-dev-build}
      DOCKER: 'true'
      PIPELINES_BASE_URL: ${PIPELINES_API_BASE_URL}
      PIPELINES_API_KEY: ${PIPELINES_API_KEY}
    ports:
      - '80:8080'
    volumes:
      - ./data/webui:/app/backend/data
    healthcheck:
      test: ['CMD', 'curl', '--silent', '--fail', 'http://localhost:8080/health']
      interval: 30s
      timeout: 10s
      retries: 5
    command: ['bash', 'start.sh']
    restart: unless-stopped

  pipelines:
    build:
      context: ../pipelines # Update this path to your actual pipelines directory
      dockerfile: Dockerfile
      args:
        USE_CUDA: ${USE_CUDA:-false}
        USE_CUDA_VER: ${USE_CUDA_VER:-cu121}
    environment:
      ENV: prod
      PORT: 9099
      USE_CUDA_DOCKER: ${USE_CUDA:-false}
      USE_CUDA_DOCKER_VER: ${USE_CUDA_VER:-cu121}
    ports:
      - '9099:9099'
    volumes:
      - ./data/pipelines:/app/backend/data
    restart: always
    extra_hosts:
      - 'host.docker.internal:host-gateway'
